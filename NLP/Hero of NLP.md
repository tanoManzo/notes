[[NLP]]

**Chris Manning** (Stanford):  
- Linguistics, AI, mentioned Chomsky (human cannot learn language only from the data), 
- Transformer Architecture, Attention (soft tree structure), what transformers learn during the training (e.g., co-reference facts), 
- paper on Neural Machine Translation (foundation of NLP, Attention, probabilistic model technique, etc.).
- Language models give you probability distribution of a sequence of words
