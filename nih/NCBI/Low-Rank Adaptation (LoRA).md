Let W0, W1 ∈ R m×n define the same weight matrix before and after task-specific fine-tuning, and we have W1 = W0 + ∆W, where ∆W ∈ R m×n represents the change of each weight element during the fine-tuning. In ordinary fine-tuning, we independently update each weight based on its corresponding gradient, while in LoRA, we represent ∆W with a low-rank decomposition ∆W = BA, where B ∈ R m×r , A ∈ R r×n , and r ≪ m, r ≪ n. Modeling ∆W with low-rank decomposition reduces the number of trainable parameters from m × n to r × (m + n), leading to significant improvement in training time and memory usage. 